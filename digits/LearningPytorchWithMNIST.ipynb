{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor# tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.nn.functional as F           # l]ayers, activations and more\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from my_funcs import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data\n",
    "trainD = pd.read_csv('digit-recognizer/train.csv')\n",
    "#testD = pd.read_csv('digit-recognizer/test.csv')\n",
    "#sampleD = pd.read_csv('digit-recognizer/sample_submission.csv')\n",
    "trainD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = trainD['label']\n",
    "X_train = trainD.drop(['label'],1,inplace=False).values/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of test data is 8400\n",
      "The number of epochs is 83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "testSize = 1.0/5\n",
    "featuresTrain, featuresTest, targetsTrain, targetsTest = train_test_split(X_train, y_train.values, test_size=testSize, random_state=42)\n",
    "testLen = len(targetsTest)\n",
    "print(\"The length of test data is {}\".format(testLen))\n",
    "\n",
    "device = torch.device('cuda')     # Default CUDA device\n",
    "\n",
    "featuresTrain = torch.from_numpy(featuresTrain).type(torch.float32)\n",
    "#featuresTrain = featuresTrain.to(device) #not sure if it is better memory managment to do so BEFORE the dataloader\n",
    "\n",
    "featuresTest = torch.from_numpy(featuresTest).type(torch.float32)\n",
    "#featuresTest = featuresTest.to(device)\n",
    "\n",
    "targetsTrain = torch.from_numpy(targetsTrain).type(torch.LongTensor)\n",
    "#targetsTrain = targetsTrain.to(device)\n",
    "\n",
    "targetsTest = torch.from_numpy(targetsTest).type(torch.LongTensor)\n",
    "#targetsTest = targetsTest.to(device)\n",
    "\n",
    "featuresSize = 28*28\n",
    "targetsSize = 10\n",
    "\n",
    "# batch_size, epoch and iteration\n",
    "batch_size = 280\n",
    "n_iters = 10000\n",
    "num_epochs = n_iters / (len(featuresTrain) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(\"The number of epochs is {}\".format(num_epochs))\n",
    "\n",
    "train = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\n",
    "test = torch.utils.data.TensorDataset(featuresTest,targetsTest)\n",
    "\n",
    "train_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(test, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 5, 7], [1, 4, 1, 2, 1]]\n",
      "[   1    2    3    4    5    6    7    8   10   12   14   15   16   20\n",
      "   21   24   25   28   30   35   40   42   48   50   56   60   70   75\n",
      "   80   84  100  105  112  120  140  150  168  175  200  210  240  280\n",
      "  300  336  350  400  420  525  560  600  700  840 1050 1200 1400 1680\n",
      " 2100 2800 4200 8400]\n"
     ]
    }
   ],
   "source": [
    "#divisors = div(40768/784)\n",
    "number = 8400\n",
    "divisors = div(number)\n",
    "prime_Divisors = pDiv(number)\n",
    "print(prime_Divisors)\n",
    "print(np.sort(divisors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Logistic Regression Model\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        # Linear part\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        # There should be logistic function right?\n",
    "        # However logistic function in pytorch is in loss function\n",
    "        # So actually we do not forget to put it, it is only at next parts\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "    \n",
    "\n",
    "# create logistic regression model\n",
    "model = LogisticRegressionModel(featuresSize, targetsSize)\n",
    "\n",
    "# Cross Entropy Loss  \n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer \n",
    "learning_rate = 0.002\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
      "Wall time: 9.06 µs\n",
      "Iteration: 500  Loss: 1.5569393634796143  Accuracy: 75%\n",
      "Iteration: 1000  Loss: 1.2565058469772339  Accuracy: 80%\n",
      "Iteration: 1500  Loss: 0.9675431251525879  Accuracy: 82%\n",
      "Iteration: 2000  Loss: 0.8557437062263489  Accuracy: 83%\n",
      "Iteration: 2500  Loss: 0.7758675217628479  Accuracy: 84%\n",
      "Iteration: 3000  Loss: 0.7215481400489807  Accuracy: 84%\n",
      "Iteration: 3500  Loss: 0.7615463137626648  Accuracy: 85%\n",
      "Iteration: 4000  Loss: 0.726697564125061  Accuracy: 85%\n",
      "Iteration: 4500  Loss: 0.680799126625061  Accuracy: 85%\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Traning the Model\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        # Define variables\n",
    "        train = Variable(images.view(-1, 28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "        \n",
    "        # Calculate softmax and cross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        # Prediction\n",
    "        if count % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Predict test dataset\n",
    "            for images, labels in test_loader: \n",
    "                test = Variable(images.view(-1, 28*28))\n",
    "                \n",
    "                # Forward propagation\n",
    "                outputs = model(test)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += len(labels)\n",
    "                \n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "        if count % 500 == 0:\n",
    "            # Print Loss\n",
    "            print('Iteration: {}  Loss: {}  Accuracy: {}%'.format(count, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Neural Network Model\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_layer, output_dim):\n",
    "        super(ANN, self).__init__()\n",
    "        # First Layer\n",
    "        self.f1 = nn.Linear(input_dim,  hidden_layer[0])\n",
    "        self.ac1 = nn.ReLU()\n",
    "        # Second Layer\n",
    "        self.f2 = nn.Linear(hidden_layer[0],  hidden_layer[1])\n",
    "        self.ac2 = nn.Tanh()\n",
    "        # Third Layer\n",
    "        self.f3 = nn.Linear(hidden_layer[1],  hidden_layer[2])\n",
    "        self.ac3 = nn.ELU()\n",
    "        #Final Layer\n",
    "        self.f4 = nn.Linear(hidden_layer[2],output_dim)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.f1(x)\n",
    "        out = self.ac1(out)\n",
    "        out = self.f2(out)\n",
    "        out = self.ac2(out)\n",
    "        out = self.f3(out)\n",
    "        out = self.ac3(out)\n",
    "        out = self.f4(out)\n",
    "        return out\n",
    "    \n",
    "hidden_layer = [1000,200,100]\n",
    "# create neural network model\n",
    "model = ANN(featuresSize, hidden_layer, targetsSize)\n",
    "#model.to(device)\n",
    "\n",
    "# Cross Entropy Loss  \n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer \n",
    "learning_rate = 0.02\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Traning the Model\n",
    "#model.to(device)\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "#with torch.cuda.device(0):\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "#            images = images.to(device)\n",
    "#           labels = labels.to(device)\n",
    "        # Define variables\n",
    "        train = Variable(images.view(-1, 28*28))\n",
    "\n",
    "\n",
    "        labels = Variable(labels)\n",
    "\n",
    "\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "\n",
    "\n",
    "        # Calculate softmax and cross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "\n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        count += 1\n",
    "\n",
    "        # Prediction\n",
    "        if count % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Predict test dataset\n",
    "            for images, labels in test_loader: \n",
    "                #images = images.to(device)\n",
    "                #labels = labels.to(device)\n",
    "                test = Variable(images.view(-1, 28*28))\n",
    "\n",
    "                # Forward propagation\n",
    "                outputs = model(test)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "\n",
    "                # Total number of labels\n",
    "                total += len(labels)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct / float(total)\n",
    "\n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "        if count % 500 == 0:\n",
    "            # Print Loss\n",
    "            print('Iteration: {}  Loss: {}  Accuracy: {}%'.format(count, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.to(device)\n",
    "with torch.cuda.device(0):\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Define variables\n",
    "            train = Variable(images.view(-1, 28*28))\n",
    "            labels = Variable(labels)\n",
    "\n",
    "\n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward propagation\n",
    "            outputs = model(train)\n",
    "            outputs = outputs.to(device)\n",
    "\n",
    "            # Calculate softmax and cross entropy loss\n",
    "            loss = error(outputs, labels)\n",
    "\n",
    "            # Calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            count += 1\n",
    "\n",
    "            # Prediction\n",
    "            if count % 500 == 0:\n",
    "                # Calculate Accuracy         \n",
    "                correct = 0\n",
    "                total = 0\n",
    "                # Predict test dataset\n",
    "                for images, labels in test_loader: \n",
    "                    images = images.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    test = Variable(images.view(-1, 28*28))\n",
    "\n",
    "                    # Forward propagation\n",
    "                    outputs = model(test)\n",
    "                    outputs = outputs.to(device)\n",
    "\n",
    "                    # Get predictions from the maximum value\n",
    "                    predicted = torch.max(outputs.data, 1)[1]\n",
    "                    \n",
    "                    # Total number of labels\n",
    "                    total += len(labels)\n",
    "\n",
    "                    # Total correct predictions\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "                accuracy = 100 * correct / float(total)\n",
    "\n",
    "                # store loss and iteration\n",
    "                loss_list.append(loss.data)\n",
    "                iteration_list.append(count)\n",
    "            if count % 500 == 0:\n",
    "                # Print Loss\n",
    "                print('Iteration: {}  Loss: {}  Accuracy: {}%'.format(count, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create convolutional network Model\n",
    "class conVolNN(nn.Module):\n",
    "        \n",
    "    def __init__(self, hidden_layer, output_dim):\n",
    "        super(conVolNN, self).__init__()\n",
    "        # First convolutional layer: \n",
    "        self.conv1 = nn.Conv2d(in_channels= 1, out_channels = hidden_layer[0], kernel_size = 5, stride = 1, padding = 0)\n",
    "        self.ac1 = nn.ReLU() #One image object in (N,C,H,W). (N,1,28,28) to (N,hidden_layer[0],24,24)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2) #(N,hidden_layer[0],24,24) to (N,hidden_layer[0],12,12)\n",
    "        \n",
    "        # Second convolutional layer:\n",
    "        self.conv2 = nn.Conv2d(in_channels= hidden_layer[0], out_channels = hidden_layer[1], kernel_size = 3, stride = 1, padding = 0)\n",
    "        self.ac2 = nn.ReLU()#(N,hidden_layer[0],12,12) to (N,hidden_layer[1],10,10)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2) #(N,hidden_layer[0],10,10) to (N,hidden_layer[0],5,5)\n",
    "        \n",
    "        # Third convolutional layer:\n",
    "        self.conv3 = nn.Conv2d(in_channels= hidden_layer[1], out_channels = hidden_layer[2], kernel_size = 2, stride = 1, padding = 0)\n",
    "        self.ac3 = nn.ReLU()#(N,hidden_layer[0],5,5) to (N,hidden_layer[1],4,4)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2) #(N,hidden_layer[0],4,4) to (N,hidden_layer[0],2,2)\n",
    "        \n",
    "        #Final Layer\n",
    "        self.f = nn.Linear(hidden_layer[2]*2*2,hidden_layer[3])\n",
    "        self.fac = nn.Sigmoid()\n",
    "        self.f1 = nn.Linear(hidden_layer[3],output_dim)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.ac1(out)\n",
    "        out = self.pool1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.ac2(out)\n",
    "        out = self.pool2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.ac3(out)\n",
    "        out = self.pool3(out)\n",
    "        out = out.view(out.size(0),-1) # Don't forget to flatten before the final linear transformation.\n",
    "        out = self.f(out) #The logistic transformation is on the loss function.\n",
    "        out = self.fac(out)\n",
    "        out = self.f1(out) #The logistic transformation is on the loss function.\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    # Create ANN\n",
    "model = conVolNN([32,32,16,200],targetsSize)\n",
    "\n",
    "# Cross Entropy Loss \n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create convolutional network Model\n",
    "class conVolNN(nn.Module):\n",
    "        \n",
    "    def __init__(self, hidden_layer, output_dim):\n",
    "        super(conVolNN, self).__init__()\n",
    "        # First convolutional layer: \n",
    "        self.conv1 = nn.Conv2d(in_channels= 1, out_channels = hidden_layer[0], kernel_size = 5, stride = 1,padding=2)\n",
    "        self.ac1 = nn.ReLU() \n",
    "        self.conv11 = nn.Conv2d(in_channels= hidden_layer[0], out_channels = hidden_layer[0], kernel_size = 5, stride = 1, padding = 2)\n",
    "        self.ac11 = nn.ReLU() \n",
    "        self.conv12 = nn.Conv2d(in_channels= hidden_layer[0], out_channels = hidden_layer[0], kernel_size = 5, stride = 1)\n",
    "        self.ac12 = nn.ReLU() \n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2) #(N,hidden_layer[0],24,24) to (N,hidden_layer[0],12,12)\n",
    "        self.drop1 = nn.Dropout2d(p = 0.1)\n",
    "        \n",
    "        # Second convolutional layer:\n",
    "        self.conv2 = nn.Conv2d(in_channels= hidden_layer[0], out_channels = hidden_layer[1], kernel_size = 3, stride = 1, padding = 1)                                                \n",
    "        self.ac2 = nn.ReLU()#(N,hidden_layer[0],12,12) to (N,hidden_layer[1],10,10)\n",
    "        self.conv21 = nn.Conv2d(in_channels= hidden_layer[1], out_channels = hidden_layer[1], kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.ac21 = nn.ReLU()#(N,hidden_layer[0],12,12) to (N,hidden_layer[1],10,10)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2) #(N,hidden_layer[0],10,10) to (N,hidden_layer[0],5,5)\n",
    "        self.drop2 = nn.Dropout2d(p = 0.2)\n",
    "        \n",
    "        # Third convolutional layer:\n",
    "        self.conv3 = nn.Conv2d(in_channels= hidden_layer[1], out_channels = hidden_layer[2], kernel_size = 2, stride = 1, padding = 0)\n",
    "        self.ac3 = nn.ReLU()#(N,hidden_layer[0],5,5) to (N,hidden_layer[1],4,4)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2) #(N,hidden_layer[0],4,4) to (N,hidden_layer[0],2,2)\n",
    "        \n",
    "        #Final Layers\n",
    "        self.f = nn.Linear(hidden_layer[2]*2*2,hidden_layer[3])\n",
    "        self.fac = nn.Tanh()\n",
    "        self.f1 = nn.Linear(hidden_layer[3],output_dim)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.ac1(out)\n",
    "        out = self.conv11(out)\n",
    "        out = self.ac11(out)\n",
    "        out = self.conv12(out)\n",
    "        out = self.ac12(out)\n",
    "        out = self.pool1(out)\n",
    "        out = self.drop1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.ac2(out)\n",
    "        out = self.conv21(out)\n",
    "        out = self.ac21(out)\n",
    "        out = self.pool2(out)\n",
    "        out = self.drop2(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.ac3(out)\n",
    "        out = self.pool3(out)\n",
    "        \n",
    "        out = out.view(out.size(0),-1) # Don't forget to flatten before the final linear transformation.\n",
    "        out = self.f(out) #The logistic transformation is on the loss function.\n",
    "        out = self.fac(out)\n",
    "        out = self.f1(out) #The logistic transformation is on the loss function.\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    # Create ANN\n",
    "model = conVolNN([32,64,64,280],targetsSize)\n",
    "\n",
    "# Cross Entropy Loss \n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[80,25,37,50], gamma=0.75)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=80, gamma=0.5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.75, patience=8, \n",
    "                                             verbose=True, threshold=0.00001, threshold_mode='rel',\n",
    "                                             cooldown=1, min_lr=1e-8, eps=1e-08)\n",
    "\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n",
      "Iteration: 21001  Loss: 0.0012755325296893716  Accuracy: 98.73809523809524 %\n",
      "Epoch   174: reducing learning rate of group 0 to 3.1676e-03.\n",
      "10\n",
      "15\n",
      "Epoch   184: reducing learning rate of group 0 to 2.3757e-03.\n",
      "20\n",
      "Iteration: 22501  Loss: 0.0017504214774817228  Accuracy: 98.71428571428571 %\n",
      "25\n",
      "Epoch   194: reducing learning rate of group 0 to 1.7818e-03.\n",
      "30\n",
      "Iteration: 24001  Loss: 0.0034754311200231314  Accuracy: 98.71428571428571 %\n",
      "35\n",
      "40\n",
      "Epoch   207: reducing learning rate of group 0 to 1.3363e-03.\n",
      "45\n",
      "Iteration: 25501  Loss: 0.0012975624995306134  Accuracy: 98.72619047619048 %\n",
      "50\n",
      "Epoch   217: reducing learning rate of group 0 to 1.0023e-03.\n",
      "55\n",
      "Iteration: 27001  Loss: 0.0007567303255200386  Accuracy: 98.72619047619048 %\n",
      "60\n",
      "Epoch   227: reducing learning rate of group 0 to 7.5169e-04.\n",
      "65\n",
      "70\n",
      "Iteration: 28501  Loss: 0.0016801765887066722  Accuracy: 98.94047619047619 %\n",
      "Epoch   237: reducing learning rate of group 0 to 5.6377e-04.\n",
      "75\n",
      "80\n",
      "Epoch   247: reducing learning rate of group 0 to 4.2283e-04.\n",
      "98.76443001443002 0.06975087468171427\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "# CNN model training\n",
    "model.to(device)\n",
    "with torch.cuda.device(0):\n",
    "    for epoch in range(num_epochs):\n",
    "        if(epoch % 5==0): print(epoch)\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            train = Variable(images.view(batch_size,1,28,28))\n",
    "            labels = Variable(labels)\n",
    "\n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward propagation\n",
    "            outputs = model(train)\n",
    "\n",
    "            # Calculate softmax and ross entropy loss\n",
    "            loss = error(outputs, labels)\n",
    "\n",
    "            # Calculating gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            \n",
    "            optimizer.step()\n",
    "            count += 1\n",
    "            if count % 60 == 0:\n",
    "                # Calculate Accuracy         \n",
    "                correct = 0\n",
    "                total = 0\n",
    "                # Iterate through test dataset\n",
    "                for images, labels in test_loader:\n",
    "\n",
    "                    images = images.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    test = Variable(images.view(batch_size,1,28,28))\n",
    "\n",
    "                    # Forward propagation\n",
    "                    outputs = model(test)\n",
    "\n",
    "                    # Get predictions from the maximum value\n",
    "                    predicted = torch.max(outputs.data, 1)[1]\n",
    "\n",
    "                    # Total number of labels\n",
    "                    total += len(labels)\n",
    "\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "                accuracy = 100 * float(correct) / float(total)\n",
    "\n",
    "                # store loss and iteration\n",
    "                loss_list.append(loss.data)\n",
    "                iteration_list.append(count)\n",
    "                accuracy_list.append(accuracy)\n",
    "                if (count) % 500 == 0:\n",
    "                    # Print Loss\n",
    "                    print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count+1, loss.item(), accuracy))\n",
    "\n",
    "        scheduler.step(accuracy)                 \n",
    "print(np.mean(accuracy_list[len(accuracy_list)+1-int(n_iters/100):]), np.std(accuracy_list[len(accuracy_list)+1-int(n_iters/100):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./candidate_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch, median, std\n",
      "27 98.72619047619048 9.235241774919228\n",
      "55 98.72619047619048 0.10983137506633264\n",
      "83 98.73809523809524 0.07535112441173927\n",
      "110 98.75 0.0704744029517342\n",
      "138 98.76190476190476 0.06860983962705611\n",
      "166 98.76190476190476 0.06641414605122868\n",
      "193 98.76190476190476 0.06665050524570937\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(iteration_list,accuracy_list)\n",
    "plt.ylim(97.5,99.7)\n",
    "avgSec(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33600"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)\n",
    "len(featuresTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Helper function to calculate the average accuracy of the last training run.\n",
    "def avgSec(array):\n",
    "        distance = 60\n",
    "        print(\"Epoch, median, std\")\n",
    "        for i in range(0,int(count/2/distance),int(n_iters/4/distance)):\n",
    "            print(int(num_epochs/3*(i/int(n_iters/distance/4)+1)), np.median(accuracy_list[i:i+n_iters]),np.std(accuracy_list[i:i+n_iters]))\n",
    "            \n",
    "#avgSec(accuracy_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        train = Variable(images.view(batch_size,1,28,28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "        \n",
    "        # Calculate softmax and ross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "        if count % 50 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                \n",
    "                test = Variable(images.view(batch_size,1,28,28))\n",
    "                \n",
    "                # Forward propagation\n",
    "                outputs = model(test)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += len(labels)\n",
    "                \n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "            if (count) % 500 == 0:\n",
    "                # Print Loss\n",
    "                print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count+1, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
