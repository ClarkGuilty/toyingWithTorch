{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor# tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.nn.functional as F           # l]ayers, activations and more\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from my_funcs import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data\n",
    "trainD = pd.read_csv('digit-recognizer/train.csv')\n",
    "#testD = pd.read_csv('digit-recognizer/test.csv')\n",
    "#sampleD = pd.read_csv('digit-recognizer/sample_submission.csv')\n",
    "trainD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = trainD['label']\n",
    "X_train = trainD.drop(['label'],1,inplace=False).values/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda')     # Default CUDA device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of test data is 8400\n",
      "The number of epochs is 125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "testSize = 1.0/5\n",
    "featuresTrain, featuresTest, targetsTrain, targetsTest = train_test_split(X_train, y_train.values, test_size=testSize, random_state=42)\n",
    "testLen = len(targetsTest)\n",
    "print(\"The length of test data is {}\".format(testLen))\n",
    "\n",
    "\n",
    "featuresTrain = torch.from_numpy(featuresTrain).type(torch.float32)\n",
    "#featuresTrain = featuresTrain.to(device) #not sure if it is better memory managment to do so BEFORE the dataloader\n",
    "\n",
    "featuresTest = torch.from_numpy(featuresTest).type(torch.float32)\n",
    "#featuresTest = featuresTest.to(device)\n",
    "\n",
    "targetsTrain = torch.from_numpy(targetsTrain).type(torch.LongTensor)\n",
    "#targetsTrain = targetsTrain.to(device)\n",
    "\n",
    "targetsTest = torch.from_numpy(targetsTest).type(torch.LongTensor)\n",
    "#targetsTest = targetsTest.to(device)\n",
    "\n",
    "featuresSize = 28*28\n",
    "targetsSize = 10\n",
    "\n",
    "# batch_size, epoch and iteration\n",
    "batch_size = 420\n",
    "n_iters = 10000\n",
    "num_epochs = n_iters / (len(featuresTrain) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(\"The number of epochs is {}\".format(num_epochs))\n",
    "\n",
    "train = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\n",
    "test = torch.utils.data.TensorDataset(featuresTest,targetsTest)\n",
    "\n",
    "train_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(test, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8400\n",
      "[[1, 2, 3, 5, 7], [1, 4, 1, 2, 1]]\n",
      "[   1    2    3    4    5    6    7    8   10   12   14   15   16   20\n",
      "   21   24   25   28   30   35   40   42   48   50   56   60   70   75\n",
      "   80   84  100  105  112  120  140  150  168  175  200  210  240  280\n",
      "  300  336  350  400  420  525  560  600  700  840 1050 1200 1400 1680\n",
      " 2100 2800 4200 8400]\n"
     ]
    }
   ],
   "source": [
    "#divisors = div(40768/784)\n",
    "number = testSize*42000\n",
    "print(int(number))\n",
    "divisors = div(number)\n",
    "prime_Divisors = pDiv(number)\n",
    "print(prime_Divisors)\n",
    "print(np.sort(divisors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create convolutional network Model\n",
    "class conVolNN(nn.Module):\n",
    "        \n",
    "    def __init__(self, hidden_layer, output_dim):\n",
    "        super(conVolNN, self).__init__()\n",
    "        # First convolutional layer: \n",
    "        self.conv1 = nn.Conv2d(in_channels= 1, out_channels = hidden_layer[0], kernel_size = 3, stride = 1,padding=1)\n",
    "        self.ac1 = nn.ReLU() \n",
    "        self.conv11 = nn.Conv2d(in_channels= hidden_layer[0], out_channels = hidden_layer[0], kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.ac11 = nn.ReLU() \n",
    "        #self.conv12 = nn.Conv2d(in_channels= hidden_layer[0], out_channels = hidden_layer[0], kernel_size = 3, stride = 1)\n",
    "        #self.ac12 = nn.ReLU() \n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2) #(N,hidden_layer[0],28,28) to (N,hidden_layer[0],14,14)\n",
    "        #self.drop1 = nn.Dropout2d(p = 0.1)\n",
    "        \n",
    "        # Second convolutional layer:\n",
    "        self.conv2 = nn.Conv2d(in_channels= hidden_layer[0], out_channels = hidden_layer[1], kernel_size = 5, stride = 1, padding = 2)                                                \n",
    "        self.ac2 = nn.ReLU()\n",
    "        self.conv21 = nn.Conv2d(in_channels= hidden_layer[1], out_channels = hidden_layer[1], kernel_size = 5, stride = 1, padding = 2)\n",
    "        self.ac21 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2) #(N,hidden_layer[1],14,14) to (N,hidden_layer[1],7,7)\n",
    "        #self.drop2 = nn.Dropout2d(p = 0.2)\n",
    "        \n",
    "        # Third convolutional layer:\n",
    "        self.conv3 = nn.Conv2d(in_channels= hidden_layer[1], out_channels = hidden_layer[2], kernel_size = 7, stride = 1, padding = 3)                                                \n",
    "        self.ac3 = nn.ReLU()\n",
    "        self.conv31 = nn.Conv2d(in_channels= hidden_layer[2], out_channels = hidden_layer[2], kernel_size = 7, stride = 1, padding = 3)\n",
    "        self.ac31 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=3,stride = 3) #(N,hidden_layer[2],7,7) to (N,hidden_layer[2],2,2)\n",
    "                                \n",
    "        # Forth convolutional layer:\n",
    "        self.conv4 = nn.Conv2d(in_channels= hidden_layer[2], out_channels = hidden_layer[3], kernel_size = 7, stride = 1, padding = 3)\n",
    "        self.batch4 = nn.BatchNorm2d(hidden_layer[3])\n",
    "        self.ac4 = nn.ReLU()#(N,hidden_layer[0],5,5) to (N,hidden_layer[1],4,4)\n",
    "        #self.pool3 = nn.MaxPool2d(kernel_size=2) #(N,hidden_layer[0],4,4) to (N,hidden_layer[0],2,2)\n",
    "        \n",
    "        #Final Layers\n",
    "        self.f5 = nn.Linear(hidden_layer[3]*2*2,hidden_layer[3])\n",
    "        self.ac5 = nn.ReLU()\n",
    "        self.drop5 = nn.Dropout2d(p = 0.5)\n",
    "        self.f51 = nn.Linear(hidden_layer[3],hidden_layer[4])\n",
    "        self.ac51 = nn.ReLU()\n",
    "        self.drop51 = nn.Dropout2d(p = 0.5)\n",
    "        self.f52 = nn.Linear(hidden_layer[4],output_dim)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.ac1(out)\n",
    "        #print(out.shape)\n",
    "        out = self.conv11(out)\n",
    "        out = self.ac11(out)\n",
    "        #print(out.shape)\n",
    "        out = self.pool1(out)\n",
    "        #print(out.shape)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.ac2(out)\n",
    "        #print(out.shape)\n",
    "        out = self.conv21(out)\n",
    "        out = self.ac21(out)\n",
    "       # print(out.shape)\n",
    "        out = self.pool2(out)\n",
    "        #print(out.shape)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.ac3(out)\n",
    "        #print(out.shape)\n",
    "        out = self.conv31(out)\n",
    "        out = self.ac31(out)\n",
    "        #print(out.shape)\n",
    "        out = self.pool3(out)\n",
    "        #print(out.shape)\n",
    "                                \n",
    "        out = self.conv4(out)\n",
    "        #print(out.shape)\n",
    "        out = self.batch4(out)\n",
    "        out = self.ac4(out)\n",
    "        #\n",
    "        #print(out.shape)\n",
    "        \n",
    "        out = out.view(out.size(0),-1) # Don't forget to flatten before the final linear transformation.\n",
    "        out = self.f5(out) #The logistic transformation is on the loss function.\n",
    "        out = self.ac5(out)\n",
    "        out = self.drop5(out)\n",
    "        out = self.f51(out) #The logistic transformation is on the loss function.\n",
    "        out = self.ac51(out)\n",
    "        out = self.drop51(out)\n",
    "        out = self.f52(out) #The logistic transformation is on the loss function.\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ANN\n",
    "model = conVolNN([32,64,128,256,100],targetsSize)\n",
    "\n",
    "# Cross Entropy Loss \n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[80,25,37,50], gamma=0.75)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=80, gamma=0.5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.75, patience=8, \n",
    "                                             verbose=True, threshold=0.00001, threshold_mode='rel',\n",
    "                                             cooldown=1, min_lr=1e-8, eps=1e-08)\n",
    "\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n",
      "10\n",
      "15\n",
      "Iteration: 1501  Loss: 0.0016306252218782902  Accuracy: 98.92857142857143 %\n",
      "20\n",
      "25\n",
      "30\n",
      "Epoch    32: reducing learning rate of group 0 to 7.5000e-02.\n",
      "35\n",
      "Iteration: 3001  Loss: 0.001410776050761342  Accuracy: 99.08333333333333 %\n",
      "40\n",
      "Epoch    42: reducing learning rate of group 0 to 5.6250e-02.\n",
      "45\n",
      "50\n",
      "55\n",
      "Iteration: 4501  Loss: 0.0006137870368547738  Accuracy: 99.11904761904762 %\n",
      "Epoch    58: reducing learning rate of group 0 to 4.2188e-02.\n",
      "60\n",
      "65\n",
      "70\n",
      "Iteration: 6001  Loss: 0.0003254776820540428  Accuracy: 99.14285714285714 %\n",
      "Epoch    74: reducing learning rate of group 0 to 3.1641e-02.\n",
      "75\n",
      "80\n",
      "Epoch    84: reducing learning rate of group 0 to 2.3730e-02.\n",
      "85\n",
      "90\n",
      "Iteration: 7501  Loss: 0.001543909078463912  Accuracy: 99.08333333333333 %\n",
      "95\n",
      "100\n",
      "Epoch   101: reducing learning rate of group 0 to 1.7798e-02.\n",
      "105\n",
      "110\n",
      "Epoch   111: reducing learning rate of group 0 to 1.3348e-02.\n",
      "Iteration: 9001  Loss: 0.0009369214531034231  Accuracy: 99.10714285714286 %\n",
      "115\n",
      "120\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0011e-02.\n",
      "99.14730639730638 0.053336045832904404\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "# CNN model training\n",
    "model.to(device)\n",
    "with torch.cuda.device(0):\n",
    "    for epoch in range(num_epochs):\n",
    "        if(epoch % 5==0): print(epoch)\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            train = Variable(images.view(batch_size,1,28,28))\n",
    "            labels = Variable(labels)\n",
    "\n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward propagation\n",
    "            outputs = model(train)\n",
    "\n",
    "            # Calculate softmax and ross entropy loss\n",
    "            loss = error(outputs, labels)\n",
    "\n",
    "            # Calculating gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            \n",
    "            optimizer.step()\n",
    "            count += 1\n",
    "            if count % 60 == 0:\n",
    "                # Calculate Accuracy         \n",
    "                correct = 0\n",
    "                total = 0\n",
    "                # Iterate through test dataset\n",
    "                for images, labels in test_loader:\n",
    "\n",
    "                    images = images.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    test = Variable(images.view(batch_size,1,28,28))\n",
    "\n",
    "                    # Forward propagation\n",
    "                    outputs = model(test)\n",
    "\n",
    "                    # Get predictions from the maximum value\n",
    "                    predicted = torch.max(outputs.data, 1)[1]\n",
    "\n",
    "                    # Total number of labels\n",
    "                    total += len(labels)\n",
    "\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "                accuracy = 100 * float(correct) / float(total)\n",
    "\n",
    "                # store loss and iteration\n",
    "                loss_list.append(loss.data)\n",
    "                iteration_list.append(count)\n",
    "                accuracy_list.append(accuracy)\n",
    "                if (count) % 500 == 0:\n",
    "                    # Print Loss\n",
    "                    print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count+1, loss.item(), accuracy))\n",
    "\n",
    "        scheduler.step(accuracy)                 \n",
    "print(np.mean(accuracy_list[len(accuracy_list)+1-int(n_iters/100):]), np.std(accuracy_list[len(accuracy_list)+1-int(n_iters/100):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "testD = pd.read_csv('digit-recognizer/test.csv')\n",
    "X_test = testD.values/255\n",
    "\n",
    "\n",
    "X_test = torch.from_numpy(X_test).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test)\n",
    "# batch_size, epoch and iteration\n",
    "batch_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(\"The number of epochs is {}\".format(num_epochs))\n",
    "submission_file = open('submission_file.txt',\"w+\") \n",
    "submission_file.write(\"ImageId,Label\\n\")\n",
    "test = torch.utils.data.TensorDataset(X_test)\n",
    "\n",
    "test_loader = DataLoader(test, batch_size = batch_size, shuffle = False)\n",
    "loaded_model.to(device)\n",
    "id = 1\n",
    "with torch.cuda.device(0):\n",
    "    for i, images in enumerate(test_loader):\n",
    "            #print(images)\n",
    "            to_Test = Variable(images[0].view(batch_size,1,28,28))\n",
    "            to_Test = to_Test.to(device)\n",
    "            # Forward propagation\n",
    "            outputs = loaded_model(to_Test)\n",
    "            # Get predictions from the maximum value\n",
    "            predicted = torch.max(outputs.data, 1)[1]\n",
    "            for prediction in predicted:\n",
    "                #print(id,prediction.item())\n",
    "                submission_file.write(\"{},{}\\n\".format(id,prediction.item()))\n",
    "                id+=1\n",
    "                \n",
    "                \n",
    "                \n",
    "submission_file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28000"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "500*56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch, median, std\n",
      "41 99.11309523809524 3.826244463098002\n",
      "83 99.14285714285714 0.10020948579392941\n",
      "125 99.1547619047619 0.05569926228199614\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(iteration_list,accuracy_list)\n",
    "plt.ylim(97.5,99.7)\n",
    "avgSec(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"./candidate_Model\"\n",
    "#torch.save(model.state_dict(), \"./candidate_Model\")\n",
    "loaded_model = conVolNN([32,64,128,256,100],10)\n",
    "loaded_model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33600"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)\n",
    "len(featuresTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Helper function to calculate the average accuracy of the last training run.\n",
    "def avgSec(array):\n",
    "        distance = 60\n",
    "        print(\"Epoch, median, std\")\n",
    "        for i in range(0,int(count/2/distance),int(n_iters/4/distance)):\n",
    "            print(int(num_epochs/3*(i/int(n_iters/distance/4)+1)), np.median(accuracy_list[i:i+n_iters]),np.std(accuracy_list[i:i+n_iters]))\n",
    "            \n",
    "#avgSec(accuracy_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create convolutional network Model\n",
    "class conVolNN(nn.Module):\n",
    "        \n",
    "    def __init__(self, hidden_layer, output_dim):\n",
    "        super(conVolNN, self).__init__()\n",
    "        # First convolutional layer: \n",
    "        self.conv1 = nn.Conv2d(in_channels= 1, out_channels = hidden_layer[0], kernel_size = 5, stride = 1, padding = 0)\n",
    "        self.ac1 = nn.ReLU() #One image object in (N,C,H,W). (N,1,28,28) to (N,hidden_layer[0],24,24)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2) #(N,hidden_layer[0],24,24) to (N,hidden_layer[0],12,12)\n",
    "        \n",
    "        # Second convolutional layer:\n",
    "        self.conv2 = nn.Conv2d(in_channels= hidden_layer[0], out_channels = hidden_layer[1], kernel_size = 3, stride = 1, padding = 0)\n",
    "        self.ac2 = nn.ReLU()#(N,hidden_layer[0],12,12) to (N,hidden_layer[1],10,10)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2) #(N,hidden_layer[0],10,10) to (N,hidden_layer[0],5,5)\n",
    "        \n",
    "        # Third convolutional layer:\n",
    "        self.conv3 = nn.Conv2d(in_channels= hidden_layer[1], out_channels = hidden_layer[2], kernel_size = 2, stride = 1, padding = 0)\n",
    "        self.ac3 = nn.ReLU()#(N,hidden_layer[0],5,5) to (N,hidden_layer[1],4,4)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2) #(N,hidden_layer[0],4,4) to (N,hidden_layer[0],2,2)\n",
    "        \n",
    "        #Final Layer\n",
    "        self.f = nn.Linear(hidden_layer[2]*2*2,hidden_layer[3])\n",
    "        self.fac = nn.Sigmoid()\n",
    "        self.f1 = nn.Linear(hidden_layer[3],output_dim)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.ac1(out)\n",
    "        out = self.pool1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.ac2(out)\n",
    "        out = self.pool2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.ac3(out)\n",
    "        out = self.pool3(out)\n",
    "        out = out.view(out.size(0),-1) # Don't forget to flatten before the final linear transformation.\n",
    "        out = self.f(out) #The logistic transformation is on the loss function.\n",
    "        out = self.fac(out)\n",
    "        out = self.f1(out) #The logistic transformation is on the loss function.\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    # Create ANN\n",
    "model = conVolNN([32,32,16,200],targetsSize)\n",
    "\n",
    "# Cross Entropy Loss \n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[500, 1, 28, 28]' is invalid for input of size 313600",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-15a4a246c7cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;31m# Forward propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[500, 1, 28, 28]' is invalid for input of size 313600"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        train = Variable(images.view(batch_size,1,28,28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "        \n",
    "        # Calculate softmax and ross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "        if count % 50 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                \n",
    "                test = Variable(images.view(batch_size,1,28,28))\n",
    "                \n",
    "                # Forward propagation\n",
    "                outputs = model(test)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += len(labels)\n",
    "                \n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "            if (count) % 500 == 0:\n",
    "                # Print Loss\n",
    "                print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count+1, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
