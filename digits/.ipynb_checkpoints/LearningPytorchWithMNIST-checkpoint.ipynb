{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor# tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.nn.functional as F           # l]ayers, activations and more\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "trainD = pd.read_csv('digit-recognizer/train.csv')\n",
    "#testD = pd.read_csv('digit-recognizer/test.csv')\n",
    "#sampleD = pd.read_csv('digit-recognizer/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = trainD['label']\n",
    "X_train = trainD.drop(['label'],1,inplace=False).values/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of epochs is 12\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "featuresTrain, featuresTest, targetsTrain, targetsTest = train_test_split(X_train, y_train.values, test_size=0.05, random_state=42)\n",
    "\n",
    "featuresTrain = torch.from_numpy(featuresTrain).type(torch.float32)\n",
    "featuresTest = torch.from_numpy(featuresTest).type(torch.float32)\n",
    "targetsTrain = torch.from_numpy(targetsTrain).type(torch.LongTensor)\n",
    "targetsTest = torch.from_numpy(targetsTest).type(torch.LongTensor)\n",
    "\n",
    "featuresSize = 28*28\n",
    "targetsSize = 10\n",
    "\n",
    "# batch_size, epoch and iteration\n",
    "batch_size = 100\n",
    "n_iters = 5000\n",
    "num_epochs = n_iters / (len(featuresTrain) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(\"The number of epochs is {}\".format(num_epochs))\n",
    "\n",
    "train = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\n",
    "test = torch.utils.data.TensorDataset(featuresTest,targetsTest)\n",
    "\n",
    "train_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(test, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Logistic Regression Model\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        # Linear part\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        # There should be logistic function right?\n",
    "        # However logistic function in pytorch is in loss function\n",
    "        # So actually we do not forget to put it, it is only at next parts\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "    \n",
    "\n",
    "# create logistic regression model\n",
    "model = LogisticRegressionModel(featuresSize, targetsSize)\n",
    "\n",
    "# Cross Entropy Loss  \n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer \n",
    "learning_rate = 0.002\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500  Loss: 1.5683104991912842  Accuracy: 77%\n",
      "Iteration: 1000  Loss: 1.2436202764511108  Accuracy: 81%\n",
      "Iteration: 1500  Loss: 0.9736413359642029  Accuracy: 82%\n",
      "Iteration: 2000  Loss: 0.850018322467804  Accuracy: 84%\n",
      "Iteration: 2500  Loss: 0.7633339762687683  Accuracy: 84%\n",
      "Iteration: 3000  Loss: 0.7209938764572144  Accuracy: 85%\n",
      "Iteration: 3500  Loss: 0.7593697905540466  Accuracy: 85%\n",
      "Iteration: 4000  Loss: 0.7360780835151672  Accuracy: 85%\n",
      "Iteration: 4500  Loss: 0.6821443438529968  Accuracy: 85%\n"
     ]
    }
   ],
   "source": [
    "# Traning the Model\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        # Define variables\n",
    "        train = Variable(images.view(-1, 28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "        \n",
    "        # Calculate softmax and cross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        # Prediction\n",
    "        if count % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Predict test dataset\n",
    "            for images, labels in test_loader: \n",
    "                test = Variable(images.view(-1, 28*28))\n",
    "                \n",
    "                # Forward propagation\n",
    "                outputs = model(test)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += len(labels)\n",
    "                \n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "        if count % 500 == 0:\n",
    "            # Print Loss\n",
    "            print('Iteration: {}  Loss: {}  Accuracy: {}%'.format(count, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Neural Network Model\n",
    "class ANN(nn.Module):\n",
    "        \n",
    "    def __init__(self, input_dim, hidden_layer, output_dim):\n",
    "        super(ANN, self).__init__()\n",
    "        # First Layer\n",
    "        self.f1 = nn.Linear(input_dim,  hidden_layer[0])\n",
    "        self.ac1 = nn.ReLU()\n",
    "        # Second Layer\n",
    "        self.f2 = nn.Linear(hidden_layer[0],  hidden_layer[1])\n",
    "        self.ac2 = nn.Tanh()\n",
    "        # Third Layer\n",
    "        self.f3 = nn.Linear(hidden_layer[1],  hidden_layer[2])\n",
    "        self.ac3 = nn.ELU()\n",
    "        #Final Layer\n",
    "        self.f4 = nn.Linear(hidden_layer[2],output_dim)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.f1(x)\n",
    "        out = self.ac1(out)\n",
    "        out = self.f2(out)\n",
    "        out = self.ac2(out)\n",
    "        out = self.f3(out)\n",
    "        out = self.ac3(out)\n",
    "        out = self.f4(out)\n",
    "        return out\n",
    "    \n",
    "hidden_layer = [120,100,200]\n",
    "# create neural network model\n",
    "model = ANN(featuresSize, hidden_layer, targetsSize)\n",
    "\n",
    "# Cross Entropy Loss  \n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer \n",
    "learning_rate = 0.02\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500  Loss: 0.8176902532577515  Accuracy: 79%\n",
      "Iteration: 1000  Loss: 0.45539647340774536  Accuracy: 88%\n",
      "Iteration: 1500  Loss: 0.36614808440208435  Accuracy: 90%\n",
      "Iteration: 2000  Loss: 0.25194403529167175  Accuracy: 91%\n",
      "Iteration: 2500  Loss: 0.2621469795703888  Accuracy: 93%\n",
      "Iteration: 3000  Loss: 0.22559908032417297  Accuracy: 94%\n",
      "Iteration: 3500  Loss: 0.2081308364868164  Accuracy: 94%\n",
      "Iteration: 4000  Loss: 0.17853786051273346  Accuracy: 94%\n",
      "Iteration: 4500  Loss: 0.1457626223564148  Accuracy: 94%\n"
     ]
    }
   ],
   "source": [
    "# Traning the Model\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        # Define variables\n",
    "        train = Variable(images.view(-1, 28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "        \n",
    "        # Calculate softmax and cross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        # Prediction\n",
    "        if count % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Predict test dataset\n",
    "            for images, labels in test_loader: \n",
    "                test = Variable(images.view(-1, 28*28))\n",
    "                \n",
    "                # Forward propagation\n",
    "                outputs = model(test)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += len(labels)\n",
    "                \n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "        if count % 500 == 0:\n",
    "            # Print Loss\n",
    "            print('Iteration: {}  Loss: {}  Accuracy: {}%'.format(count, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create convolutional network Model\n",
    "class conVolNN(nn.Module):\n",
    "        \n",
    "    def __init__(self, hidden_layer, output_dim):\n",
    "        super(conVolNN, self).__init__()\n",
    "        # First convolutional layer: \n",
    "        self.conv1 = nn.Conv2d(in_channels= 1, out_channels = hidden_layer[0], kernel_size = 5, stride = 1, padding = 0)\n",
    "        self.ac1 = nn.ReLU() #One image object in (N,C,H,W). (N,1,28,28) to (N,hidden_layer[0],24,24)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2) #(N,hidden_layer[0],24,24) to (N,hidden_layer[0],12,12)\n",
    "        \n",
    "        # Second convolutional layer:\n",
    "        self.conv2 = nn.Conv2d(in_channels= hidden_layer[0], out_channels = hidden_layer[1], kernel_size = 5, stride = 1, padding = 0)\n",
    "        self.ac2 = nn.ReLU()#(N,hidden_layer[0],12,12) to (N,hidden_layer[1],8,8)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2) #(N,hidden_layer[0],8,8) to (N,hidden_layer[0],4,4)\n",
    "        \n",
    "        #Final Layer\n",
    "        self.f = nn.Linear(hidden_layer[1]*4*4,output_dim)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.ac1(out)\n",
    "        out = self.pool1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.ac2(out)\n",
    "        out = self.pool2(out)\n",
    "        out = out.view(out.size(0),-1) # Don't forget to flatten before the final linear transformation.\n",
    "        out = self.f(out) #The logistic transformation is on the loss function.\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    # Create ANN\n",
    "model = conVolNN([16,32],targetsSize)\n",
    "\n",
    "# Cross Entropy Loss \n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 501  Loss: 0.055172599852085114  Accuracy: 98.00 %\n",
      "Iteration: 1001  Loss: 0.00641353614628315  Accuracy: 98.00 %\n",
      "Iteration: 1501  Loss: 0.03905360773205757  Accuracy: 98.00 %\n"
     ]
    }
   ],
   "source": [
    "# CNN model training\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        train = Variable(images.view(batch_size,1,28,28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "        \n",
    "        # Calculate softmax and ross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "        if count % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                \n",
    "                test = Variable(images.view(batch_size,1,28,28))\n",
    "                \n",
    "                # Forward propagation\n",
    "                outputs = model(test)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += len(labels)\n",
    "                \n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "            if (count) % 500 == 0:\n",
    "                # Print Loss\n",
    "                print('Iteration: {}  Loss: {}  Accuracy: {:.3f} %'.format(count+1, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
