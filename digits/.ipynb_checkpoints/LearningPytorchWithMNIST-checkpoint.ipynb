{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor# tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.nn.functional as F           # l]ayers, activations and more\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from my_funcs import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data\n",
    "trainD = pd.read_csv('digit-recognizer/train.csv')\n",
    "#testD = pd.read_csv('digit-recognizer/test.csv')\n",
    "#sampleD = pd.read_csv('digit-recognizer/sample_submission.csv')\n",
    "trainD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = trainD['label']\n",
    "X_train = trainD.drop(['label'],1,inplace=False).values/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of test data is 8400\n",
      "The number of epochs is 83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "testSize = 1.0/5\n",
    "featuresTrain, featuresTest, targetsTrain, targetsTest = train_test_split(X_train, y_train.values, test_size=testSize, random_state=42)\n",
    "testLen = len(targetsTest)\n",
    "print(\"The length of test data is {}\".format(testLen))\n",
    "\n",
    "device = torch.device('cuda')     # Default CUDA device\n",
    "\n",
    "featuresTrain = torch.from_numpy(featuresTrain).type(torch.float32)\n",
    "#featuresTrain = featuresTrain.to(device) #not sure if it is better memory managment to do so BEFORE the dataloader\n",
    "\n",
    "featuresTest = torch.from_numpy(featuresTest).type(torch.float32)\n",
    "#featuresTest = featuresTest.to(device)\n",
    "\n",
    "targetsTrain = torch.from_numpy(targetsTrain).type(torch.LongTensor)\n",
    "#targetsTrain = targetsTrain.to(device)\n",
    "\n",
    "targetsTest = torch.from_numpy(targetsTest).type(torch.LongTensor)\n",
    "#targetsTest = targetsTest.to(device)\n",
    "\n",
    "featuresSize = 28*28\n",
    "targetsSize = 10\n",
    "\n",
    "# batch_size, epoch and iteration\n",
    "batch_size = 280\n",
    "n_iters = 10000\n",
    "num_epochs = n_iters / (len(featuresTrain) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(\"The number of epochs is {}\".format(num_epochs))\n",
    "\n",
    "train = torch.utils.data.TensorDataset(featuresTrain,targetsTrain)\n",
    "test = torch.utils.data.TensorDataset(featuresTest,targetsTest)\n",
    "\n",
    "train_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(test, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3, 5, 7], [1, 4, 1, 2, 1]]\n",
      "[   1    2    3    4    5    6    7    8   10   12   14   15   16   20\n",
      "   21   24   25   28   30   35   40   42   48   50   56   60   70   75\n",
      "   80   84  100  105  112  120  140  150  168  175  200  210  240  280\n",
      "  300  336  350  400  420  525  560  600  700  840 1050 1200 1400 1680\n",
      " 2100 2800 4200 8400]\n"
     ]
    }
   ],
   "source": [
    "#divisors = div(40768/784)\n",
    "number = 8400\n",
    "divisors = div(number)\n",
    "prime_Divisors = pDiv(number)\n",
    "print(prime_Divisors)\n",
    "print(np.sort(divisors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Logistic Regression Model\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        # Linear part\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        # There should be logistic function right?\n",
    "        # However logistic function in pytorch is in loss function\n",
    "        # So actually we do not forget to put it, it is only at next parts\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "    \n",
    "\n",
    "# create logistic regression model\n",
    "model = LogisticRegressionModel(featuresSize, targetsSize)\n",
    "\n",
    "# Cross Entropy Loss  \n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer \n",
    "learning_rate = 0.002\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
      "Wall time: 9.06 µs\n",
      "Iteration: 500  Loss: 1.5569393634796143  Accuracy: 75%\n",
      "Iteration: 1000  Loss: 1.2565058469772339  Accuracy: 80%\n",
      "Iteration: 1500  Loss: 0.9675431251525879  Accuracy: 82%\n",
      "Iteration: 2000  Loss: 0.8557437062263489  Accuracy: 83%\n",
      "Iteration: 2500  Loss: 0.7758675217628479  Accuracy: 84%\n",
      "Iteration: 3000  Loss: 0.7215481400489807  Accuracy: 84%\n",
      "Iteration: 3500  Loss: 0.7615463137626648  Accuracy: 85%\n",
      "Iteration: 4000  Loss: 0.726697564125061  Accuracy: 85%\n",
      "Iteration: 4500  Loss: 0.680799126625061  Accuracy: 85%\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Traning the Model\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        # Define variables\n",
    "        train = Variable(images.view(-1, 28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "        \n",
    "        # Calculate softmax and cross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        # Prediction\n",
    "        if count % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Predict test dataset\n",
    "            for images, labels in test_loader: \n",
    "                test = Variable(images.view(-1, 28*28))\n",
    "                \n",
    "                # Forward propagation\n",
    "                outputs = model(test)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += len(labels)\n",
    "                \n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "        if count % 500 == 0:\n",
    "            # Print Loss\n",
    "            print('Iteration: {}  Loss: {}  Accuracy: {}%'.format(count, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Neural Network Model\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_layer, output_dim):\n",
    "        super(ANN, self).__init__()\n",
    "        # First Layer\n",
    "        self.f1 = nn.Linear(input_dim,  hidden_layer[0])\n",
    "        self.ac1 = nn.ReLU()\n",
    "        # Second Layer\n",
    "        self.f2 = nn.Linear(hidden_layer[0],  hidden_layer[1])\n",
    "        self.ac2 = nn.Tanh()\n",
    "        # Third Layer\n",
    "        self.f3 = nn.Linear(hidden_layer[1],  hidden_layer[2])\n",
    "        self.ac3 = nn.ELU()\n",
    "        #Final Layer\n",
    "        self.f4 = nn.Linear(hidden_layer[2],output_dim)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.f1(x)\n",
    "        out = self.ac1(out)\n",
    "        out = self.f2(out)\n",
    "        out = self.ac2(out)\n",
    "        out = self.f3(out)\n",
    "        out = self.ac3(out)\n",
    "        out = self.f4(out)\n",
    "        return out\n",
    "    \n",
    "hidden_layer = [1000,200,100]\n",
    "# create neural network model\n",
    "model = ANN(featuresSize, hidden_layer, targetsSize)\n",
    "#model.to(device)\n",
    "\n",
    "# Cross Entropy Loss  \n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer \n",
    "learning_rate = 0.02\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Traning the Model\n",
    "#model.to(device)\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "#with torch.cuda.device(0):\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "#            images = images.to(device)\n",
    "#           labels = labels.to(device)\n",
    "        # Define variables\n",
    "        train = Variable(images.view(-1, 28*28))\n",
    "\n",
    "\n",
    "        labels = Variable(labels)\n",
    "\n",
    "\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "\n",
    "\n",
    "        # Calculate softmax and cross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "\n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        count += 1\n",
    "\n",
    "        # Prediction\n",
    "        if count % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Predict test dataset\n",
    "            for images, labels in test_loader: \n",
    "                #images = images.to(device)\n",
    "                #labels = labels.to(device)\n",
    "                test = Variable(images.view(-1, 28*28))\n",
    "\n",
    "                # Forward propagation\n",
    "                outputs = model(test)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "\n",
    "                # Total number of labels\n",
    "                total += len(labels)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct / float(total)\n",
    "\n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "        if count % 500 == 0:\n",
    "            # Print Loss\n",
    "            print('Iteration: {}  Loss: {}  Accuracy: {}%'.format(count, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.to(device)\n",
    "with torch.cuda.device(0):\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Define variables\n",
    "            train = Variable(images.view(-1, 28*28))\n",
    "            labels = Variable(labels)\n",
    "\n",
    "\n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward propagation\n",
    "            outputs = model(train)\n",
    "            outputs = outputs.to(device)\n",
    "\n",
    "            # Calculate softmax and cross entropy loss\n",
    "            loss = error(outputs, labels)\n",
    "\n",
    "            # Calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            count += 1\n",
    "\n",
    "            # Prediction\n",
    "            if count % 500 == 0:\n",
    "                # Calculate Accuracy         \n",
    "                correct = 0\n",
    "                total = 0\n",
    "                # Predict test dataset\n",
    "                for images, labels in test_loader: \n",
    "                    images = images.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    test = Variable(images.view(-1, 28*28))\n",
    "\n",
    "                    # Forward propagation\n",
    "                    outputs = model(test)\n",
    "                    outputs = outputs.to(device)\n",
    "\n",
    "                    # Get predictions from the maximum value\n",
    "                    predicted = torch.max(outputs.data, 1)[1]\n",
    "                    \n",
    "                    # Total number of labels\n",
    "                    total += len(labels)\n",
    "\n",
    "                    # Total correct predictions\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "                accuracy = 100 * correct / float(total)\n",
    "\n",
    "                # store loss and iteration\n",
    "                loss_list.append(loss.data)\n",
    "                iteration_list.append(count)\n",
    "            if count % 500 == 0:\n",
    "                # Print Loss\n",
    "                print('Iteration: {}  Loss: {}  Accuracy: {}%'.format(count, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create convolutional network Model\n",
    "class conVolNN(nn.Module):\n",
    "        \n",
    "    def __init__(self, hidden_layer, output_dim):\n",
    "        super(conVolNN, self).__init__()\n",
    "        # First convolutional layer: \n",
    "        self.conv1 = nn.Conv2d(in_channels= 1, out_channels = hidden_layer[0], kernel_size = 5, stride = 1, padding = 0)\n",
    "        self.ac1 = nn.ReLU() #One image object in (N,C,H,W). (N,1,28,28) to (N,hidden_layer[0],24,24)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2) #(N,hidden_layer[0],24,24) to (N,hidden_layer[0],12,12)\n",
    "        \n",
    "        # Second convolutional layer:\n",
    "        self.conv2 = nn.Conv2d(in_channels= hidden_layer[0], out_channels = hidden_layer[1], kernel_size = 3, stride = 1, padding = 0)\n",
    "        self.ac2 = nn.ReLU()#(N,hidden_layer[0],12,12) to (N,hidden_layer[1],10,10)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2) #(N,hidden_layer[0],10,10) to (N,hidden_layer[0],5,5)\n",
    "        \n",
    "        # Third convolutional layer:\n",
    "        self.conv3 = nn.Conv2d(in_channels= hidden_layer[1], out_channels = hidden_layer[2], kernel_size = 2, stride = 1, padding = 0)\n",
    "        self.ac3 = nn.ReLU()#(N,hidden_layer[0],5,5) to (N,hidden_layer[1],4,4)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2) #(N,hidden_layer[0],4,4) to (N,hidden_layer[0],2,2)\n",
    "        \n",
    "        #Final Layer\n",
    "        self.f = nn.Linear(hidden_layer[2]*2*2,hidden_layer[3])\n",
    "        self.fac = nn.Sigmoid()\n",
    "        self.f1 = nn.Linear(hidden_layer[3],output_dim)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.ac1(out)\n",
    "        out = self.pool1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.ac2(out)\n",
    "        out = self.pool2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.ac3(out)\n",
    "        out = self.pool3(out)\n",
    "        out = out.view(out.size(0),-1) # Don't forget to flatten before the final linear transformation.\n",
    "        out = self.f(out) #The logistic transformation is on the loss function.\n",
    "        out = self.fac(out)\n",
    "        out = self.f1(out) #The logistic transformation is on the loss function.\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    # Create ANN\n",
    "model = conVolNN([32,32,16,200],targetsSize)\n",
    "\n",
    "# Cross Entropy Loss \n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create convolutional network Model\n",
    "class conVolNN(nn.Module):\n",
    "        \n",
    "    def __init__(self, hidden_layer, output_dim):\n",
    "        super(conVolNN, self).__init__()\n",
    "        # First convolutional layer: \n",
    "        self.conv1 = nn.Conv2d(in_channels= 1, out_channels = hidden_layer[0], kernel_size = 5, stride = 1,padding=2)\n",
    "        self.ac1 = nn.ReLU() \n",
    "        self.conv11 = nn.Conv2d(in_channels= hidden_layer[0], out_channels = hidden_layer[0], kernel_size = 5, stride = 1, padding = 2)\n",
    "        self.ac11 = nn.ReLU() \n",
    "        self.conv12 = nn.Conv2d(in_channels= hidden_layer[0], out_channels = hidden_layer[0], kernel_size = 5, stride = 1)\n",
    "        self.ac12 = nn.ReLU() \n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2) #(N,hidden_layer[0],24,24) to (N,hidden_layer[0],12,12)\n",
    "        self.drop1 = nn.Dropout2d(p = 0.1)\n",
    "        \n",
    "        # Second convolutional layer:\n",
    "        self.conv2 = nn.Conv2d(in_channels= hidden_layer[0], out_channels = hidden_layer[1], kernel_size = 3, stride = 1, padding = 1)                                                \n",
    "        self.ac2 = nn.ReLU()#(N,hidden_layer[0],12,12) to (N,hidden_layer[1],10,10)\n",
    "        self.conv21 = nn.Conv2d(in_channels= hidden_layer[1], out_channels = hidden_layer[1], kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.ac21 = nn.ReLU()#(N,hidden_layer[0],12,12) to (N,hidden_layer[1],10,10)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2) #(N,hidden_layer[0],10,10) to (N,hidden_layer[0],5,5)\n",
    "        self.drop2 = nn.Dropout2d(p = 0.2)\n",
    "        \n",
    "        # Third convolutional layer:\n",
    "        self.conv3 = nn.Conv2d(in_channels= hidden_layer[1], out_channels = hidden_layer[2], kernel_size = 2, stride = 1, padding = 0)\n",
    "        self.ac3 = nn.ReLU()#(N,hidden_layer[0],5,5) to (N,hidden_layer[1],4,4)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2) #(N,hidden_layer[0],4,4) to (N,hidden_layer[0],2,2)\n",
    "        \n",
    "        #Final Layers\n",
    "        self.f = nn.Linear(hidden_layer[2]*2*2,hidden_layer[3])\n",
    "        self.fac = nn.Tanh()\n",
    "        self.f1 = nn.Linear(hidden_layer[3],output_dim)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.ac1(out)\n",
    "        out = self.conv11(out)\n",
    "        out = self.ac11(out)\n",
    "        out = self.conv12(out)\n",
    "        out = self.ac12(out)\n",
    "        out = self.pool1(out)\n",
    "        out = self.drop1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.ac2(out)\n",
    "        out = self.conv21(out)\n",
    "        out = self.ac21(out)\n",
    "        out = self.pool2(out)\n",
    "        out = self.drop2(out)\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.ac3(out)\n",
    "        out = self.pool3(out)\n",
    "        \n",
    "        out = out.view(out.size(0),-1) # Don't forget to flatten before the final linear transformation.\n",
    "        out = self.f(out) #The logistic transformation is on the loss function.\n",
    "        out = self.fac(out)\n",
    "        out = self.f1(out) #The logistic transformation is on the loss function.\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    # Create ANN\n",
    "model = conVolNN([32,64,64,280],targetsSize)\n",
    "\n",
    "# Cross Entropy Loss \n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[80,25,37,50], gamma=0.75)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=80, gamma=0.5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.75, patience=8, \n",
    "                                             verbose=True, threshold=0.00001, threshold_mode='rel',\n",
    "                                             cooldown=1, min_lr=1e-8, eps=1e-08)\n",
    "\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n",
      "Iteration: 21001  Loss: 0.0012755325296893716  Accuracy: 98.73809523809524 %\n",
      "Epoch   174: reducing learning rate of group 0 to 3.1676e-03.\n",
      "10\n",
      "15\n",
      "Epoch   184: reducing learning rate of group 0 to 2.3757e-03.\n",
      "20\n",
      "Iteration: 22501  Loss: 0.0017504214774817228  Accuracy: 98.71428571428571 %\n",
      "25\n",
      "Epoch   194: reducing learning rate of group 0 to 1.7818e-03.\n",
      "30\n",
      "Iteration: 24001  Loss: 0.0034754311200231314  Accuracy: 98.71428571428571 %\n",
      "35\n",
      "40\n",
      "Epoch   207: reducing learning rate of group 0 to 1.3363e-03.\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "# CNN model training\n",
    "model.to(device)\n",
    "with torch.cuda.device(0):\n",
    "    for epoch in range(num_epochs):\n",
    "        if(epoch % 5==0): print(epoch)\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            train = Variable(images.view(batch_size,1,28,28))\n",
    "            labels = Variable(labels)\n",
    "\n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward propagation\n",
    "            outputs = model(train)\n",
    "\n",
    "            # Calculate softmax and ross entropy loss\n",
    "            loss = error(outputs, labels)\n",
    "\n",
    "            # Calculating gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            \n",
    "            optimizer.step()\n",
    "            count += 1\n",
    "            if count % 60 == 0:\n",
    "                # Calculate Accuracy         \n",
    "                correct = 0\n",
    "                total = 0\n",
    "                # Iterate through test dataset\n",
    "                for images, labels in test_loader:\n",
    "\n",
    "                    images = images.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    test = Variable(images.view(batch_size,1,28,28))\n",
    "\n",
    "                    # Forward propagation\n",
    "                    outputs = model(test)\n",
    "\n",
    "                    # Get predictions from the maximum value\n",
    "                    predicted = torch.max(outputs.data, 1)[1]\n",
    "\n",
    "                    # Total number of labels\n",
    "                    total += len(labels)\n",
    "\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "                accuracy = 100 * float(correct) / float(total)\n",
    "\n",
    "                # store loss and iteration\n",
    "                loss_list.append(loss.data)\n",
    "                iteration_list.append(count)\n",
    "                accuracy_list.append(accuracy)\n",
    "                if (count) % 500 == 0:\n",
    "                    # Print Loss\n",
    "                    print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count+1, loss.item(), accuracy))\n",
    "\n",
    "        scheduler.step(accuracy)                 \n",
    "print(np.mean(accuracy_list[len(accuracy_list)+1-int(n_iters/100):]), np.std(accuracy_list[len(accuracy_list)+1-int(n_iters/100):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(the_model.state_dict(), \"candidate_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch, median, std\n",
      "27 98.69047619047619 11.262402241912588\n",
      "55 98.71428571428571 0.1199314071180539\n",
      "83 98.72619047619048 0.07664632974869447\n",
      "110 98.73809523809524 0.07121854413717572\n",
      "138 98.73809523809524 0.06969500905769747\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(iteration_list,accuracy_list)\n",
    "plt.ylim(97.5,99.7)\n",
    "avgSec(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33600"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)\n",
    "len(featuresTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Helper function to calculate the average accuracy of the last training run.\n",
    "def avgSec(array):\n",
    "        distance = 60\n",
    "        print(\"Epoch, median, std\")\n",
    "        for i in range(0,int(count/2/distance),int(n_iters/4/distance)):\n",
    "            print(int(num_epochs/3*(i/int(n_iters/distance/4)+1)), np.median(accuracy_list[i:i+n_iters]),np.std(accuracy_list[i:i+n_iters]))\n",
    "            \n",
    "#avgSec(accuracy_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        train = Variable(images.view(batch_size,1,28,28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "        \n",
    "        # Calculate softmax and ross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "        if count % 50 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                \n",
    "                test = Variable(images.view(batch_size,1,28,28))\n",
    "                \n",
    "                # Forward propagation\n",
    "                outputs = model(test)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += len(labels)\n",
    "                \n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "            if (count) % 500 == 0:\n",
    "                # Print Loss\n",
    "                print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count+1, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
